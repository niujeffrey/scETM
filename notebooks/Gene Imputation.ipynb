{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3c44cc",
   "metadata": {},
   "source": [
    "# Gene imputation\n",
    "\n",
    "Here, we try to impute missing data using multiETM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3cb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/scETM/')\n",
    "\n",
    "import os\n",
    "os.environ[ 'NUMBA_CACHE_DIR' ] = '/scratch/st-jiaruid-1/yinian/tmp/' # https://github.com/scverse/scanpy/issues/2113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2bd307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/pbs.4804264.pbsha.ib.sockeye/matplotlib-hrcqb548 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498cba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sampler import CellSampler\n",
    "from models.scETM import scETM\n",
    "from trainers.UnsupervisedTrainer import UnsupervisedTrainer\n",
    "from eval_utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9366c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sampler import CellSamplerCITE\n",
    "from models.multiETM import MultiETM\n",
    "from trainers.UnsupervisedTrainerCITE import UnsupervisedTrainerCITE\n",
    "from eval_utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e99b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': {'rna': ['/arc/project/st-jiaruid-1/yinian/pbmc/CV0902_rna.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0915_rna.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0917_rna.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0929_rna.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0939_rna.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0940_rna.h5ad'],\n",
       "  'protein': ['/arc/project/st-jiaruid-1/yinian/pbmc/CV0902_protein.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0915_protein.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0917_protein.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0929_protein.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0939_protein.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0940_protein.h5ad'],\n",
       "  'combined': ['/arc/project/st-jiaruid-1/yinian/pbmc/CV0902_combined.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0915_combined.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0917_combined.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0929_combined.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0939_combined.h5ad',\n",
       "   '/arc/project/st-jiaruid-1/yinian/pbmc/CV0940_combined.h5ad'],\n",
       "  'gene_indices': '/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/scripts/gene_indices_covid.pkl'},\n",
       " 'model_params': {'n_epochs': 12000,\n",
       "  'eval_every': 3000,\n",
       "  'cell_type_col': 'full_clustering',\n",
       "  'day': 4,\n",
       "  'donor': 'covid_healthy',\n",
       "  'rna_n_vars': 24737},\n",
       " 'ckpt_dir': '/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/results/'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml.safe_load(Path('../experiments/covid_healthy.yaml').read_text())\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d254c3",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff62e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = config['files']\n",
    "model_params = config['model_params']\n",
    "if model_params['cell_type_col'] == 'None':\n",
    "    model_params['cell_type_col'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5467a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 12292 × 24737\n",
       "    obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id', 'batch_indices'\n",
       "    obsm: 'X_pca', 'X_pca_harmony', 'X_umap'\n",
       "    layers: 'raw'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_files = files['rna']\n",
    "protein_files = files['protein']\n",
    "rna_adata = ad.concat([ad.read_h5ad(r_file) for r_file in rna_files], label=\"batch_indices\")\n",
    "protein_adata = ad.concat([ad.read_h5ad(p_file) for p_file in protein_files], label=\"batch_indices\")\n",
    "rna_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb4652",
   "metadata": {},
   "source": [
    "### Split into training and test splits\n",
    "\n",
    "The train split will not zero out the genes we are going to test, the test set will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d9718f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(np.arange(len(rna_adata)), size=int(len(rna_adata) * 0.85), replace=False)\n",
    "test_indices = np.array(list(set(np.arange(len(rna_adata))).difference(train_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fde33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/scripts/train_indices_ch.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2658e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rna_adata = rna_adata[train_indices]\n",
    "train_protein_adata = protein_adata[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0b10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rna_adata = rna_adata[test_indices].copy()\n",
    "orig_test_rna_adata = rna_adata[test_indices]\n",
    "test_protein_adata = protein_adata[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c69a3",
   "metadata": {},
   "source": [
    "Select 10% of genes to impute and set them to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89df80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On initial run, select the genes to zero out and save them in a file\n",
    "# gene_indices = np.random.choice(np.arange(rna_adata.n_vars), size=int(rna_adata.n_vars * 0.1), replace=False)\n",
    "# gene_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a199aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/scripts/gene_indices_covid2.pkl', 'wb') as f:\n",
    "#     pickle.dump(gene_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b660a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On all subsequent runs, load the saved file and zero out genes saved from there. This includes runs for \n",
    "# other models but the same dataset.\n",
    "with open('/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/scripts/gene_indices_covid2.pkl', 'rb') as f:\n",
    "    gene_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7725298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "test_rna_adata[:, gene_indices] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63dabd",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df6cb96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MultiETM(train_rna_adata.n_vars, train_protein_adata.n_vars, train_rna_adata.obs.batch_indices.nunique())\n",
    "trainer = UnsupervisedTrainerCITE(model, train_rna_adata, train_protein_adata,\n",
    "                                  ckpt_dir='/scratch/st-jiaruid-1/yinian/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56eb263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:      38.72\tnll:      38.72\tkl_delta:      166.6\tmax_norm:      131.7\tEpoch     0/12000\tNext ckpt:       0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scETM.evaluate assumes discrete cell types. Converting cell_type_col to categorical.\n",
      "2023-03-25 15:07:11.603971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-25 15:07:11.760830: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-25 15:07:14.479525: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n",
      "2023-03-25 15:07:14.479622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n",
      "2023-03-25 15:07:14.479630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/scratch/st-jiaruid-1/yinian/my_jupyter/scETM/notebooks/../src/scETM/eval_utils.py:275: FutureWarning: Setting categories in-place is deprecated and will raise in a future version. Use rename_categories instead.\n",
      "  attr_values.categories = range(nbatch)\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:378: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:378: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:378: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  cax = scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:      12.68\tnll:      12.68\tkl_delta:        494\tmax_norm:     0.2857\tEpoch   545/12000\tNext ckpt:   12000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12000\u001b[39m, eval_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12000\u001b[39m, eval_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(cell_type_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_clustering\u001b[39m\u001b[38;5;124m'\u001b[39m), n_samplers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_model_ckpt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/scETM/notebooks/../src/scETM/logging_utils.py:33\u001b[0m, in \u001b[0;36mlog_arguments.<locals>.log_arguments_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m args_kwargs_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m [args_str, kwargs_str] \u001b[38;5;28;01mif\u001b[39;00m s])\n\u001b[1;32m     32\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs_kwargs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/scETM/notebooks/../src/scETM/trainers/UnsupervisedTrainerCITE.py:270\u001b[0m, in \u001b[0;36mUnsupervisedTrainerCITE.train\u001b[0;34m(self, n_epochs, eval_every, n_samplers, kl_warmup_ratio, min_kl_weight, max_kl_weight, eval, batch_col, save_model_ckpt, record_log_path, writer, eval_result_log_path, eval_kwargs, **train_kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m next_ckpt_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m/\u001b[39m eval_every) \u001b[38;5;241m*\u001b[39m eval_every), n_epochs)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m<\u001b[39m n_epochs:\n\u001b[0;32m--> 270\u001b[0m     new_record, hyper_param_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkl_warmup_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkl_warmup_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_kl_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_kl_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_kl_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_kl_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_kwargs\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     recorder\u001b[38;5;241m.\u001b[39mupdate(new_record, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch, n_epochs, next_ckpt_epoch)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step()\n",
      "File \u001b[0;32m~/scETM/notebooks/../src/scETM/trainers/UnsupervisedTrainerCITE.py:366\u001b[0m, in \u001b[0;36mUnsupervisedTrainerCITE.do_train_step\u001b[0;34m(self, dataloader, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m hyper_param_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch, kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m, kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_warmup_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_kl_weight\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_kl_weight\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    363\u001b[0m }\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# construct data_dict\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# train for one step, record tracked items (e.g. loss)\u001b[39;00m\n\u001b[1;32m    369\u001b[0m new_record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, data_dict, hyper_param_dict)\n",
      "File \u001b[0;32m~/scETM/notebooks/../src/scETM/batch_sampler.py:311\u001b[0m, in \u001b[0;36mCellSamplerCITE._low_batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m X_protein \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_protein[batch, :]\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# X = X.tocoo()\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# cells = torch.sparse.FloatTensor(torch.LongTensor([X.row, X.col]), torch.FloatTensor(X.data), X.shape)\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     cells_gene \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mX_gene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    312\u001b[0m     cells_protein \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_protein\u001b[38;5;241m.\u001b[39mtodense())\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scipy/sparse/_base.py:939\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtodense\u001b[39m(\u001b[38;5;28mself\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ascontainer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/scipy/sparse/_compressed.py:1062\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     y \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1061\u001b[0m M, N \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39m_swap(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 1062\u001b[0m \u001b[43mcsr_todense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=12000, eval_every=12000, eval_kwargs = dict(cell_type_col = 'full_clustering'), n_samplers=1, save_model_ckpt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d40d4f",
   "metadata": {},
   "source": [
    "## Run the forward model and see what gets imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a7a51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import spmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d878a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules.\n",
    "\n",
    "    It is assumed that the predictions are not constant.\n",
    "\n",
    "    Returns the average of each sample's Pearson correlation coefficient\n",
    "\n",
    "    Source: https://www.kaggle.com/code/xiafire/lb-t15-msci-multiome-catboostregressor#Predicting\n",
    "    \"\"\"\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shapes are different.\")\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3df2d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings (emb) which represent the topic mixture proportions\n",
    "emb, nll = model.get_cell_embeddings_and_nll(test_rna_adata, test_protein_adata, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54b0892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rna_adata.obs.batch_indices.nunique() > 1:\n",
    "    batch = torch.LongTensor(test_rna_adata.obs['batch_indices'].astype('category').cat.codes)\n",
    "else:\n",
    "    batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ea403bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model decoder to reconstruct the data, the reconstruction will try to impute the zeroed out data.\n",
    "pred = model.decode(torch.Tensor(emb['theta']).to('cuda'), batch).detach().cpu().numpy()\n",
    "pred = pred[:, :rna_adata.n_vars]\n",
    "pred = np.exp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e34de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 1978)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_pred = pred[:, gene_indices]\n",
    "indexed_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4477eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 1978)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data = orig_test_rna_adata[:, :model_params['rna_n_vars']].copy()\n",
    "if isinstance(true_data.X, spmatrix):\n",
    "    true_data.X = true_data.X.toarray()\n",
    "true_data = true_data.X / true_data.X.sum(1, keepdims=True)\n",
    "indexed_true_data = true_data[:, gene_indices]\n",
    "indexed_true_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca6d7a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2981219e-07"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(indexed_pred, indexed_true_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46684491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/arc/project/st-jiaruid-1/yinian/tensorflow-gpu/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_score(indexed_true_data, indexed_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
